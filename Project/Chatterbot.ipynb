{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chatterbot\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "#!python -m spacy download en_core_web_trf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_text(text):\n",
    "    text = text.replace(\"â\\x80\\x99\", \"'\")\n",
    "    if \"ð\" in text:\n",
    "        for word in text.split():\n",
    "            if \"ð\" in word:\n",
    "                text = text.replace(word, \"EMOJI\")\n",
    "    return text\n",
    "\n",
    "\n",
    "#This chunk of code reads the json files for FACEBOOK MESSENGER MESSAGES\n",
    "person = \"Amit\" #Which person do you want the chat bot to replicate?\n",
    "sender = \"Amit Krishnaiyer\"\n",
    "path = \"../Messages/\" + person\n",
    "conversation_list = [] #List of all conversations in an organized format\n",
    "speaker_list = [] #List of everything the speaker said\n",
    "for filename in os.listdir(path):\n",
    "    if filename[-4:] == \"json\":\n",
    "        conversation = []\n",
    "        f = open(path + \"/\" + filename)\n",
    "        data = json.load(f)[\"messages\"]\n",
    "        for message in data:\n",
    "            if \"content\" in message:\n",
    "                the_message = fix_text(message[\"content\"])\n",
    "                conversation.append((the_message, message[\"sender_name\"]))\n",
    "                if sender == message[\"sender_name\"]:\n",
    "                    speaker_list.append(the_message)\n",
    "        conversation_list.append(conversation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('amit', 132), ('played,', 115), ('u', 111), ('t', 82), ('yea', 80), ('ur', 74), ('cuz', 66), ('like', 65), ('lol', 53), ('get', 52), (\"i'm\", 49), ('n', 47), ('also', 42), ('lke', 42), ('thnk', 38), ('rlly', 38), ('w', 37), ('ab', 29), ('emoji', 28), ('go', 28), ('well', 27), ('tho', 27), (\"'m\", 26), ('good', 26), ('f', 26), ('would', 25), ('one', 25), ('got', 24), ('see', 24), ('even', 24)]\n"
     ]
    }
   ],
   "source": [
    "#This block of code gets the speaker's most common used words\n",
    "word_lis = []\n",
    "for message in speaker_list:\n",
    "    message = preprocesser(message, True, False, False, True, True)# (text, lower, punctuation, named_entity, white_space, stop_words)\n",
    "    words = message.split()\n",
    "    for word in words:\n",
    "        if word != \"\":\n",
    "            word_lis.append(word)\n",
    "\n",
    "# Pass the split_it list to instance of Counter class.\n",
    "\n",
    "Counter = Counter(word_lis)\n",
    "  \n",
    "# most_common() produces k frequently encountered\n",
    "# input values and their respective counts.\n",
    "most_occur = Counter.most_common(30)\n",
    "  \n",
    "print(most_occur)\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ORGANIZATION is a 2022 GPE Hindi-language drama film, written and directed by PERSON. Produced by PERSON, the film is based on the exodus of ORGANIZATION during the ORGANIZATION, which it portrays as a genocide. It stars PERSON, PERSON, PERSON and PERSON.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Only have to run the code below once\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "'''\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "stop_words_set = stopwords.words('english')\n",
    "custom_stop_words = [\"um\", \"uhm\", \"uh\", \"oh\", \"ok\", \"turn!\"]\n",
    "stop_words_set = set(stop_words_set + custom_stop_words)\n",
    "\n",
    "\n",
    "\n",
    "def find_and_replace(sentence):\n",
    "    dic = {}\n",
    "    for sent in nltk.sent_tokenize(sentence):\n",
    "        for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sent))):\n",
    "             if hasattr(chunk, 'label'):\n",
    "                #print(f\"{' '.join(c[0] for c in chunk):<35} {chunk.label()}\")\n",
    "                thing = ' '.join(c[0] for c in chunk)\n",
    "                dic[thing] = chunk.label()\n",
    "                #print(thing, chunk.label())\n",
    "    for key in dic:\n",
    "        sentence = sentence.replace(key, dic[key])\n",
    "    return sentence\n",
    "\n",
    "def remove_punctuation(word):\n",
    "    if word[0].isalpha() == False and word[0].isdigit() == False:\n",
    "        word = word[1:]\n",
    "    if len(word) > 0:\n",
    "        if word[-1].isalpha() == False and word[-1].isdigit() == False:\n",
    "            word = word[:-1]\n",
    "    return word\n",
    "\n",
    "\n",
    "def preprocesser(text, lower, punctuation, named_entity, white_space, stop_words):\n",
    "    if lower:\n",
    "        text = text.lower()\n",
    "    if punctuation:\n",
    "        text = remove_punctuation(text)\n",
    "    if named_entity:\n",
    "        text = find_and_replace(text)\n",
    "    if white_space:\n",
    "        text = text.strip()\n",
    "    if stop_words:\n",
    "        for word in text.split():\n",
    "            if word in stop_words_set:\n",
    "                text = text.replace(word, \"\")    \n",
    "    return text\n",
    "\n",
    "sentence = \"The Kashmir Files is a 2022 Indian Hindi-language drama film, \\\n",
    "written and directed by Vivek Agnihotri. Produced by Zee Studios, \\\n",
    "the film is based on the exodus of Kashmiri Pandits during the Kashmir Insurgency, \\\n",
    "which it portrays as a genocide. \\\n",
    "It stars Anupam Kher, Darshan Kumar, Pallavi Joshi and Mithun Chakraborty.\"\n",
    "print(find_and_replace(sentence))     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/amit/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/amit/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "from chatterbot import ChatBot\n",
    "chatbot = ChatBot(person)\n",
    "\n",
    "preprocessors=['chatterbot.preprocessors.clean_whitespace']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List Trainer: [####################] 100%\n",
      "List Trainer: [####################] 100%\n",
      "Hello!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nWhat do I consider when responding to texts?\\nHigh Priority:\\nEnergy of the message: I try to match energy: Could measure energy of message?\\nWhat is the sentiment of the message?\\nWhat are my interests at the moment?\\nWho are the people I'm talking about the most at the time. \\n\\n\\nBonus: What are they asking for- is it something I can google?\\n\\n\\nLow Priority:\\nWhat time of day is it? Do I text differently at night than day? \\n\\n\""
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from chatterbot.trainers import ListTrainer\n",
    "\n",
    "trainer = ListTrainer(chatbot)\n",
    "\n",
    "trainer.train([\n",
    "    \"Hi there!\",\n",
    "    \"Hello!!\",\n",
    "])\n",
    "\n",
    "trainer.train([\n",
    "    \"Greetings!\",\n",
    "    \"Hello!\",\n",
    "])\n",
    "response = chatbot.get_response(\"Greetings!\")\n",
    "print(response)\n",
    "\n",
    "\n",
    "'''\n",
    "What do I consider when responding to texts?\n",
    "High Priority:\n",
    "Energy of the message: I try to match energy: Could measure energy of message?\n",
    "What is the sentiment of the message?\n",
    "What are my interests at the moment?\n",
    "Who are the people I'm talking about the most at the time. \n",
    "\n",
    "\n",
    "Bonus: What are they asking for- is it something I can google?\n",
    "\n",
    "\n",
    "Low Priority:\n",
    "What time of day is it? Do I text differently at night than day? \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
